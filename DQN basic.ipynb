{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import random\n",
    "import keras\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "from keras.layers import Dense,Flatten,Dropout,Input\n",
    "from keras.models import Sequential,Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env=gym.make('CartPole-v0')\n",
    "#env.reset()\n",
    "#observation,_,_,_=env.step(0)\n",
    "#print(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "ENV_NAME='CartPole-v0'#これはstateを変数そのもので表現する感じ\n",
    "MAX_EPISODES=100\n",
    "RANDOM_RESETS=10\n",
    "MAX_STEPS=1000\n",
    "RENDER=False\n",
    "INITIAL_EPSILON=1.0\n",
    "FINAL_EPSILON=0.1\n",
    "SAVE_PATH='saved_networks/'+ENV_NAME\n",
    "LOAD=False\n",
    "LEARNING_RATE=1.0e-4\n",
    "MOMENTUM=0.95\n",
    "MIN_GRAD=0.1\n",
    "INITIALIZE_REPLAY_SIZE=80#学習が始まるまでにメモリにためておく\n",
    "MEMORY_SIZE=1000\n",
    "TARGET_NETWORK_UPDATES=1000#main&targetの共有重みの更新の頻度\n",
    "SAVE_INTERVAL=10\n",
    "BATCH_SIZE=32\n",
    "TRAIN=True\n",
    "MAX_EPSIODES_TEST=5\n",
    "GAMMA=0.9\n",
    "\n",
    "\n",
    "\"\"\"画像を入力データとするとき\"\"\"\n",
    "FRAME_WIDTH=64\n",
    "FRAME_HEIGHT=64\n",
    "STATE_LENGTH=4#一回の学習に入れる画像の枚数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent class\n",
    "class Agent():\n",
    "    \n",
    "    def __init__(self,num_actions,num_states):\n",
    "        self.num_actions=num_actions\n",
    "        self.num_states=num_states\n",
    "        self.t=0#現在のステップ数\n",
    "        self.epsilon=INITIAL_EPSILON\n",
    "        self.epsilon_step=(INITIAL_EPSILON-FINAL_EPSILON)/MAX_STEPS\n",
    "        \n",
    "        #parameters\n",
    "        self.total_q_max=0\n",
    "        self.total_reward=0\n",
    "        self.total_loss=0\n",
    "        self.episode=0\n",
    "        self.duration=0\n",
    "        \n",
    "        self.start=0\n",
    "        \n",
    "        #memory\n",
    "        self.replay_memory=deque()#端っこから情報を捨てれる\n",
    "        \n",
    "        #Q_netwrokの作成\n",
    "        self.s,self.q_values,q_network=self.build_network()#main\n",
    "        q_network_weights=q_network.trainable_weights\n",
    "        \n",
    "        self.st,self.target_q_values,target_q_network=self.build_network()#target 最適化における教師信号\n",
    "        target_q_network_weights=target_q_network.trainable_weights\n",
    "        \n",
    "        #mainとtargetのnetworkの重みを共有\n",
    "        self.update_target_network=[target_q_network_weights[i].assign(q_network_weights[i]) for i in range(len(target_q_network_weights))]\n",
    "        \n",
    "        \n",
    "        #最適化\n",
    "        self.a,self.y,self.loss,self.optimizer=self.train_op(q_network_weights)#重みを更新\n",
    "        \n",
    "        #tensorflowの実行インスタンス\n",
    "        self.sess=tf.InteractiveSession()\n",
    "        \n",
    "        self.saver=tf.train.Saver()\n",
    "        \n",
    "        #保存するdirectoryの作成\n",
    "        if not os.path.exists(SAVE_PATH):\n",
    "            os.mkdir(SAVE_PATH)\n",
    "            \n",
    "        \n",
    "        #全てのパラメータの初期化\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        #学習済みのモデルを用いるときは\n",
    "        if LOAD:\n",
    "            self.load_network()\n",
    "            \n",
    "        #共有重みの更新\n",
    "        self.sess.run(self.update_target_network)\n",
    "        \n",
    "        \n",
    "    def build_network(self):\n",
    "        s=tf.placeholder(tf.float32,[None,self.num_states])#batch_sizeを入れるテンソルを残しておく\n",
    "        \n",
    "        model=Sequential()\n",
    "        model.add(Dense(16,activation='relu',input_dim=self.num_states))\n",
    "        model.add(Dense(16,activation='relu'))\n",
    "        model.add(Dense(self.num_actions,activation='linear'))\n",
    "        \n",
    "        q_values=model(s)\n",
    "        \n",
    "        return s,q_values,model\n",
    "    \n",
    "    \n",
    "    def train_op(self,q_network_weights):\n",
    "        a=tf.placeholder(tf.int64,[None])\n",
    "        y=tf.placeholder(tf.float32,[None])\n",
    "        \n",
    "        #行動をベクトル化\n",
    "        a_onehot=tf.one_hot(a,self.num_actions,1.0,0.0)\n",
    "        q_value=tf.reduce_sum(tf.multiply(self.q_values,a_onehot),reduction_indices=1)\n",
    "        \n",
    "        #損失\n",
    "        error=tf.abs(y-q_value)\n",
    "        quardratic_part=tf.clip_by_value(error,0.0,1.0)#errorを1.0~0.0に\n",
    "        linear_part=error-quardratic_part\n",
    "        loss=tf.reduce_mean(0.5*tf.square(quardratic_part)+linear_part)\n",
    "        \n",
    "        #最適手法\n",
    "        \n",
    "        \"\"\"勾配が消失しないようにepsilon入れておく\"\"\"\n",
    "        optimizer=tf.train.RMSPropOptimizer(LEARNING_RATE,momentum=MOMENTUM,epsilon=MIN_GRAD)\n",
    "        optimizer=optimizer.minimize(loss,var_list=q_network_weights)\n",
    "        \n",
    "        \"\"\"prioritized experience replayならばerrorをここで返す\"\"\"\n",
    "        return a,y,loss,optimizer\n",
    "        \n",
    "    \n",
    "    #ε-greedyで行動選択\n",
    "    def get_action(self,state):\n",
    "        \"\"\"画像データなど一気に入れるときにはstepの中でその数だけ同じ行動をとるようにする\"\"\"\n",
    "        if np.random.rand()<self.epsilon:\n",
    "            action=random.randrange(self.num_actions)\n",
    "            \n",
    "        else:\n",
    "            action=np.argmax(self.q_values.eval(feed_dict={self.s:[np.float32(state)]}))\n",
    "            \n",
    "        if self.epsilon>=FINAL_EPSILON and self.t>=INITIALIZE_REPLAY_SIZE:\n",
    "            self.epsilon-=self.epsilon_step\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def run(self,state,action,reward,next_state,terminal):\n",
    "        \n",
    "        #報酬\n",
    "        reward=np.sign(reward)#符号だけ\n",
    "        \n",
    "        #memoryに保存\n",
    "        self.replay_memory.append((state,action,reward,next_state,terminal))\n",
    "        \n",
    "        #memoryのサイズがいっぱいになったら捨てる\n",
    "        if len(self.replay_memory)> MEMORY_SIZE:\n",
    "            self.replay_memory.popleft()#deque()を使わないならばremove()関数を作るなどする\n",
    "        \n",
    "        \"\"\"最適化の開始\"\"\"\n",
    "        if self.t>=INITIALIZE_REPLAY_SIZE:\n",
    "            self.replay()\n",
    "            \n",
    "            #共有パラメータの更新\n",
    "            if self.t%TARGET_NETWORK_UPDATES==0:\n",
    "                self.sess.run(self.update_target_network)\n",
    "            #重みの保存    \n",
    "            if self.t%SAVE_INTERVAL==0:\n",
    "                save_path=self.saver.save(self.sess,SAVE_PATH+'/'+ENV_NAME,global_step=(self.t))\n",
    "                \n",
    "        self.total_reward+=reward\n",
    "        self.total_q_max+=np.max(self.q_values.eval(feed_dict={self.s:[np.float32(state)]}))\n",
    "        self.duration+=1\n",
    "        \n",
    "        #学習の途中で終了したときその時点での結果を出力し、合計パラメータをリセット\n",
    "        if terminal:\n",
    "            elapsed_time=time.time()-self.start\n",
    "            #どの段階で終了したかを確認\n",
    "            if self.t<INITIALIZE_REPLAY_SIZE:\n",
    "                mode='random'\n",
    "            elif INITIALIZE_REPLAY_SIZE<=self.t<INITIALIZE_REPLAY_SIZE+MAX_STEPS:\n",
    "                mode='exploration'\n",
    "            else:\n",
    "                mode='exploit'\n",
    "            \n",
    "            print('episode:{0}/time_step:{1}/duration:{2}/total_reward:{3}/avg_loss:{4}/mode:{5}'\n",
    "                 .format(self.episode+1,self.t,self.duration,self.total_reward,self.total_loss/float(self.duration),mode))\n",
    "            \n",
    "            \n",
    "            self.total_reward=0\n",
    "            self.total_q_max=0\n",
    "            self.total_loss=0\n",
    "            self.episode+=1\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.t+=1\n",
    "        \n",
    "        return next_state\n",
    "    \n",
    "    \"\"\"minibatch学習\"\"\"\n",
    "    def replay(self):\n",
    "        state_batch=[]\n",
    "        action_batch=[]\n",
    "        reward_batch=[]\n",
    "        next_state_batch=[]\n",
    "        terminal_batch=[]\n",
    "        \n",
    "        \n",
    "        #memoryからサンプリングしてくる\n",
    "        minibatch=random.sample(self.replay_memory,BATCH_SIZE)\n",
    "        \n",
    "        \n",
    "        #ミニバッチの作成\n",
    "        for data in minibatch:\n",
    "            state_batch.append(data[0])\n",
    "            action_batch.append(data[1])\n",
    "            reward_batch.append(data[2])\n",
    "            next_state_batch.append(data[3])\n",
    "            terminal_batch.append(data[4])\n",
    "            \n",
    "        \n",
    "\n",
    "        terminal_batch=np.array(terminal_batch)+0#termonal_batchの数値化\n",
    "        \n",
    "        \n",
    "        target_q_values_batch=self.target_q_values.eval(feed_dict={self.st:np.float32(np.array(next_state_batch))})\n",
    "        \n",
    "        \n",
    "        #DDQNではここでactionを(s_t+1)から推定してtarget_q_values_batchを変化させる\n",
    "        #actions=np.argmax(self.q_values.eval(feed_dict={self.s:np.float32(np.array(next_state_batch))}))\n",
    "        #targte_q_values_batch=[target_q_values[i][action] for i,action in enumerate(actions)]\n",
    "        \n",
    "        y_batch=reward_batch+(1-terminal_batch)*GAMMA*np.max(target_q_values_batch,axis=1)#教師バッチ\n",
    "        \n",
    "        #学習\n",
    "        loss,_=self.sess.run([self.loss,self.optimizer],feed_dict={self.s:np.float32(np.array(state_batch)),\n",
    "                                                                  self.a:action_batch,self.y:y_batch})\n",
    "        \n",
    "        self.total_loss+=loss\n",
    "        \n",
    "        \n",
    "    \"\"\"学習済みのネットワークを用いる時\"\"\"\n",
    "    def load_network():\n",
    "        checkpoint=tf.train.get_checkpoint_state(SAVE_PATH)\n",
    "        if checkpoint and checkpoint.model_checkpoint_path:\n",
    "            self.saver.restore(self.sess,checkpoint.model_checkpoint_path)\n",
    "            print('successfully loaded')\n",
    "        else:\n",
    "            print('please training')\n",
    "            \n",
    "            \n",
    "    def get_action_at_test(self,state):\n",
    "        if np.random.rand()<0.05:\n",
    "            action=random.randrange(self.num_actions)\n",
    "        else:\n",
    "            action=np.argmax(self.q_values.eval(feed_dict={self.s:[np.float32(state)]}))\n",
    "            \n",
    "            \n",
    "        self.t+=1\n",
    "        return action\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:1/time_step:15/duration:16/total_reward:16.0/avg_loss:0.0/mode:random\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "episode:2/time_step:17/duration:18/total_reward:2.0/avg_loss:0.0/mode:random\n",
      "episode:3/time_step:20/duration:21/total_reward:3.0/avg_loss:0.0/mode:random\n",
      "episode:4/time_step:39/duration:40/total_reward:19.0/avg_loss:0.0/mode:random\n",
      "episode:5/time_step:43/duration:44/total_reward:4.0/avg_loss:0.0/mode:random\n",
      "episode:6/time_step:45/duration:46/total_reward:2.0/avg_loss:0.0/mode:random\n",
      "episode:7/time_step:54/duration:55/total_reward:9.0/avg_loss:0.0/mode:random\n",
      "episode:8/time_step:67/duration:68/total_reward:13.0/avg_loss:0.0/mode:random\n",
      "episode:9/time_step:70/duration:71/total_reward:3.0/avg_loss:0.0/mode:random\n",
      "episode:10/time_step:90/duration:91/total_reward:20.0/avg_loss:0.07575585619433896/mode:exploration\n",
      "episode:11/time_step:100/duration:101/total_reward:10.0/avg_loss:0.058448538921847204/mode:exploration\n",
      "episode:12/time_step:104/duration:105/total_reward:4.0/avg_loss:0.022949028015136718/mode:exploration\n",
      "episode:13/time_step:105/duration:106/total_reward:1.0/avg_loss:0.004835864283003897/mode:exploration\n",
      "episode:14/time_step:108/duration:109/total_reward:3.0/avg_loss:0.015217076200957693/mode:exploration\n",
      "episode:15/time_step:109/duration:110/total_reward:1.0/avg_loss:0.004847016117789529/mode:exploration\n",
      "episode:16/time_step:115/duration:116/total_reward:6.0/avg_loss:0.027330020635292447/mode:exploration\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-35eef7726d45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mterminal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#学習の実行 状態の更新\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-5e82c2ab8d96>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, state, action, reward, next_state, terminal)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;31m#重みの保存\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mSAVE_INTERVAL\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSAVE_PATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mENV_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[0;32m   1675\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1676\u001b[0m           self.export_meta_graph(\n\u001b[1;32m-> 1677\u001b[1;33m               meta_graph_filename, strip_default_attrs=strip_default_attrs)\n\u001b[0m\u001b[0;32m   1678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[1;34m(self, filename, collection_list, as_text, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs)\u001b[0m\n\u001b[0;32m   1713\u001b[0m     return export_meta_graph(\n\u001b[0;32m   1714\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1715\u001b[1;33m         \u001b[0mgraph_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1716\u001b[0m         \u001b[0msaver_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1717\u001b[0m         \u001b[0mcollection_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollection_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_def\u001b[1;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[0;32m   3248\u001b[0m     \"\"\"\n\u001b[0;32m   3249\u001b[0m     \u001b[1;31m# pylint: enable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3250\u001b[1;33m     \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3251\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_def\u001b[1;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[0;32m   3192\u001b[0m           \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3193\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3194\u001b[1;33m         \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3195\u001b[0m         \u001b[1;31m# Strip the experimental library field iff it's empty.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3196\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\google\\protobuf\\message.py\u001b[0m in \u001b[0;36mParseFromString\u001b[1;34m(self, serialized)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \"\"\"\n\u001b[0;32m    184\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMergeFromString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mMergeFromString\u001b[1;34m(self, serialized)\u001b[0m\n\u001b[0;32m   1081\u001b[0m     \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1083\u001b[1;33m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_InternalParse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# The only reason _InternalParse would return early is if it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;31m# encountered an end-group tag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mInternalParse\u001b[1;34m(self, buffer, pos, end)\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfield_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfield_desc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_UpdateOneofState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\google\\protobuf\\internal\\decoder.py\u001b[0m in \u001b[0;36mDecodeRepeatedField\u001b[1;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[0;32m    610\u001b[0m           \u001b[1;32mraise\u001b[0m \u001b[0m_DecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Truncated message.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[1;31m# Read sub-message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_InternalParse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m           \u001b[1;31m# The only reason _InternalParse would return early is if it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m           \u001b[1;31m# encountered an end-group tag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mInternalParse\u001b[1;34m(self, buffer, pos, end)\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfield_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfield_desc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_UpdateOneofState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\google\\protobuf\\internal\\decoder.py\u001b[0m in \u001b[0;36mDecodeMap\u001b[1;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[0;32m    741\u001b[0m       \u001b[1;31m# Read sub-message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m       \u001b[0msubmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m       \u001b[1;32mif\u001b[0m \u001b[0msubmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_InternalParse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    744\u001b[0m         \u001b[1;31m# The only reason _InternalParse would return early is if it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m         \u001b[1;31m# encountered an end-group tag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mInternalParse\u001b[1;34m(self, buffer, pos, end)\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfield_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfield_desc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_UpdateOneofState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\google\\protobuf\\internal\\decoder.py\u001b[0m in \u001b[0;36mDecodeField\u001b[1;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[0;32m    624\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m       \u001b[1;31m# Read length.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m       \u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocal_DecodeVarint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mMakeSubMessageDefault\u001b[1;34m(message)\u001b[0m\n\u001b[0;32m    426\u001b[0m       result._SetListener(\n\u001b[0;32m    427\u001b[0m           \u001b[0m_OneofListener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m           \u001b[1;32mif\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontaining_oneof\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m           else message._listener_for_children)\n\u001b[0;32m    430\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#main\n",
    "env=gym.make(ENV_NAME)\n",
    "NUM_ACTIONS=env.action_space.n\n",
    "NUM_STATES=env.observation_space.shape[0]\n",
    "agent=Agent(NUM_ACTIONS,NUM_STATES)#agentのインスタンス\n",
    "\n",
    "\"\"\"observationが画像であるならば計算コストを考えてresizeする\"\"\"\n",
    "def preprocessing(last_observation,observation):\n",
    "    img=np.maximum(last_observation,observation)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    img=cv2.resize(img,(FRAME_WIDTH,FRAME_HEIGHT))\n",
    "    img=np.uint8(img)#8 bit\n",
    "    \n",
    "    return np.reshape(img,(1,FRAME_WIDTH,FRAME_HEIGHT))#テンソル次元を増やす\n",
    "    \n",
    "#学習のスタート\n",
    "if TRAIN:\n",
    "    for eps in range(MAX_EPISODES):\n",
    "        terminal=False#学習の途中で終了したかの判定\n",
    "        observation=env.reset()#ゲームの初期化\n",
    "\n",
    "        #ここで初期値をランダムにするために(何もしない)を何回か行う\n",
    "        for _ in range(np.random.randint(0,RANDOM_RESETS)):\n",
    "            observation,reward,terminal,_=env.step(0)#infoはいらないので削除　no actionのindexは0\n",
    "\n",
    "        state=observation#初期状態(変数)\n",
    "        agent.start=time.time()#学習時間の計測\n",
    "        while not terminal:\n",
    "            action=agent.get_action(state)#行動のインデックスを返す\n",
    "            observation,reward,terminal,_=env.step(action)\n",
    "\n",
    "            #描画\n",
    "            if RENDER:\n",
    "                env.render()\n",
    "\n",
    "            state=agent.run(state,action,reward,observation,terminal)#学習の実行 状態の更新 \n",
    "            \n",
    "            \n",
    "else:\n",
    "    for _ in range(MAX_EPISODES_TEST):\n",
    "        terminal=False\n",
    "        observation=env.reset()\n",
    "        \n",
    "        for _ in range(np.random.randint(0,RANDOM_RESETS)):\n",
    "            observation,_,terminal,_=env.step(0)#何も行動しない\n",
    "            \n",
    "        state=observation\n",
    "        while not terminal:\n",
    "            action=agent.get_action_at_test(state)\n",
    "            observation,_,terminal,_=env.step(action)\n",
    "            env.render()\n",
    "            state=observation\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
